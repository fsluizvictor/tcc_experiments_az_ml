{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# authenticate\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "SUBSCRIPTION=\"a3f56f48-3efb-4970-81a3-e4eda598333c\"\n",
        "RESOURCE_GROUP=\"luiz.victor.dev-rg\"\n",
        "WS_NAME=\"tcc-experiments\"\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=SUBSCRIPTION,\n",
        "    resource_group_name=RESOURCE_GROUP,\n",
        "    workspace_name=WS_NAME,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1715211808916
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that the handle works correctly.  \n",
        "# If you ge an error here, modify your SUBSCRIPTION, RESOURCE_GROUP, and WS_NAME in the previous cell.\n",
        "ws = ml_client.workspaces.get(WS_NAME)\n",
        "print(ws.location,\":\", ws.resource_group)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "eastus2 : luiz.victor.dev-rg\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211809287
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DATAS = [\n",
        "    \"vrex_consolidated_2008_2017.csv\"\n",
        "]\n",
        "\n",
        "TEST_DATAS = [\n",
        "    \"vrex_consolidated_2018_2021.csv\"\n",
        "]\n",
        "\n",
        "version = \"original\"\n",
        "\n",
        "arr_data_to_train = []\n",
        "arr_data_to_test = []\n",
        "\n",
        "for to_train, to_test in zip(TRAIN_DATAS, TEST_DATAS):\n",
        "    data_to_train = ml_client.data.get(name=to_train.split(\".\")[0], version=version)\n",
        "    arr_data_to_train.append(data_to_train)\n",
        "    print(f\"Data to train asset URI: {data_to_train.path} - name: {to_train.split('.')[0]}\")\n",
        "\n",
        "    data_to_test = ml_client.data.get(name=to_test.split('.')[0], version=version)\n",
        "    arr_data_to_test.append(data_to_test)\n",
        "    print(f\"Data to test asset URI: {data_to_test.path} - name: {to_test.split('.')[0]}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data to train asset URI: azureml://subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourcegroups/luiz.victor.dev-rg/workspaces/tcc-experiments/datastores/workspaceblobstore/paths/LocalUpload/4722af391476dd8597905df3c3ae6d19/vrex_consolidated_2008_2017.csv - name: vrex_consolidated_2008_2017\nData to test asset URI: azureml://subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourcegroups/luiz.victor.dev-rg/workspaces/tcc-experiments/datastores/workspaceblobstore/paths/LocalUpload/154dc9171c762e1cab20b8998d7d1c63/vrex_consolidated_2018_2021.csv - name: vrex_consolidated_2018_2021\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211809562
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "data_prep_component = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/preparation/data_prep.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "data_prep_component = ml_client.create_or_update(data_prep_component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {data_prep_component.name} with Version {data_prep_component.version} is registered\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Component data_prep_vrex_defaults_model with Version 2024-05-08-23-43-30-2231322 is registered\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211811645
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_gbc = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/train/train_gbc.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "train_gbc = ml_client.create_or_update(train_gbc)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_gbc.name} with Version {train_gbc.version} is registered\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Component train_gbc_model with Version 2024-05-08-23-43-32-1664066 is registered\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211813256
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_nbc = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/train/train_nbc.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "train_nbc = ml_client.create_or_update(train_nbc)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_nbc.name} with Version {train_nbc.version} is registered\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Component train_nbc_model with Version 2024-05-08-23-43-33-6218937 is registered\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211814699
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_rfc = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/train/train_rfc.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "train_rfc = ml_client.create_or_update(train_rfc)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_rfc.name} with Version {train_rfc.version} is registered\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Component train_rfc_model with Version 2024-05-08-23-43-35-1402885 is registered\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211816318
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_svc = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/train/train_svc.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "train_svc = ml_client.create_or_update(train_svc)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_svc.name} with Version {train_svc.version} is registered\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Component train_svc_model with Version 2024-05-08-23-43-36-5992663 is registered\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211817869
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_xgb = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/train/train_xgb.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "train_xgb = ml_client.create_or_update(train_xgb)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_xgb.name} with Version {train_xgb.version} is registered\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Component train_xgb_model with Version 2024-05-08-23-43-38-2536869 is registered\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211819111
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL_TRIALS = 20\n",
        "CONCURRENT_TRIALS = 10\n",
        "TIMEOUT = 3600\n",
        "TIMEOUT_PLUS = 7200\n",
        "\n",
        "COMPUTE = 'serverless'\n",
        "SAMPLING_ALGORITHM = 'bayesian'\n",
        "METRIC = 'training_accuracy_score'\n",
        "GOAL = 'Maximize'\n",
        "EVALUATION_INTERVAL = 1\n",
        "DELAY_EVALUATION = 5\n",
        "\n",
        "# the dsl decorator tells the sdk that we are defining an Azure Machine Learning pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211819226
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def train_gbc_pipeline(\n",
        "    data_to_train,\n",
        "    data_to_test,\n",
        "    flag_remove_null_values,\n",
        "    flag_remove_values_by_percentage,\n",
        "    percentage_to_remove_column,\n",
        "):\n",
        "\n",
        "    data_prep_job = data_prep_component(\n",
        "        data_to_train=data_to_train,\n",
        "        data_to_test=data_to_test,\n",
        "        flag_remove_null_values=flag_remove_null_values,\n",
        "        flag_remove_values_by_percentage=flag_remove_values_by_percentage,\n",
        "        percentage_to_remove_column=percentage_to_remove_column,\n",
        "    )\n",
        "\n",
        "    train_gbc_job = train_gbc(\n",
        "        train_data=data_prep_job.outputs.train_data,  # note: using outputs from previous step\n",
        "        test_data=data_prep_job.outputs.test_data,  # note: using outputs from previous step\n",
        "        n_estimators_to_gbc=Choice(values=[50, 100, 200]),\n",
        "        learning_rate_to_gbc=Uniform(min_value=0.01, max_value=0.3),\n",
        "    )\n",
        "\n",
        "    sweep_step_to_gbc = train_gbc_job.sweep(\n",
        "        compute=COMPUTE,\n",
        "        sampling_algorithm=SAMPLING_ALGORITHM,\n",
        "        primary_metric=METRIC,\n",
        "        goal=GOAL,\n",
        "    )\n",
        "\n",
        "    sweep_step_to_gbc.set_limits(max_total_trials=2*TOTAL_TRIALS, max_concurrent_trials=CONCURRENT_TRIALS, timeout=TIMEOUT)\n",
        "\n",
        "    sweep_step_to_gbc.early_termination = MedianStoppingPolicy(delay_evaluation=DELAY_EVALUATION, evaluation_interval=EVALUATION_INTERVAL)\n"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211819442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def train_nbc_pipeline(\n",
        "    data_to_train,\n",
        "    data_to_test,\n",
        "    flag_remove_null_values,\n",
        "    flag_remove_values_by_percentage,\n",
        "    percentage_to_remove_column,\n",
        "):\n",
        "\n",
        "    data_prep_job = data_prep_component(\n",
        "        data_to_train=data_to_train,\n",
        "        data_to_test=data_to_test,\n",
        "        flag_remove_null_values=flag_remove_null_values,\n",
        "        flag_remove_values_by_percentage=flag_remove_values_by_percentage,\n",
        "        percentage_to_remove_column=percentage_to_remove_column,\n",
        "    )\n",
        "\n",
        "    train_nbc_job = train_nbc(\n",
        "        train_data=data_prep_job.outputs.train_data,  # note: using outputs from previous step\n",
        "        test_data=data_prep_job.outputs.test_data,  # note: using outputs from previous step\n",
        "    )\n",
        "\n",
        "    sweep_step_to_nbc = train_nbc_job.sweep(\n",
        "        compute=COMPUTE,\n",
        "        sampling_algorithm=SAMPLING_ALGORITHM,\n",
        "        primary_metric=METRIC,\n",
        "        goal=GOAL,\n",
        "    )\n",
        "\n",
        "    sweep_step_to_nbc.set_limits(max_total_trials=1, max_concurrent_trials=1, timeout=TIMEOUT)\n",
        "    sweep_step_to_nbc.early_termination = MedianStoppingPolicy(delay_evaluation=DELAY_EVALUATION, evaluation_interval=EVALUATION_INTERVAL)\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211819576
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def train_rfc_pipeline(\n",
        "    data_to_train,\n",
        "    data_to_test,\n",
        "    flag_remove_null_values,\n",
        "    learning_rate_to_train,\n",
        "    flag_remove_values_by_percentage,\n",
        "    percentage_to_remove_column,\n",
        "):\n",
        "\n",
        "    data_prep_job = data_prep_component(\n",
        "        data_to_train=data_to_train,\n",
        "        data_to_test=data_to_test,\n",
        "        flag_remove_null_values=flag_remove_null_values,\n",
        "        flag_remove_values_by_percentage=flag_remove_values_by_percentage,\n",
        "        percentage_to_remove_column=percentage_to_remove_column,\n",
        "    )\n",
        "\n",
        "    train_rfc_job = train_rfc(\n",
        "        train_data=data_prep_job.outputs.train_data,  # note: using outputs from previous step\n",
        "        test_data=data_prep_job.outputs.test_data,  # note: using outputs from previous step\n",
        "        n_estimators_to_rfc=Choice(values=[50, 100, 200]),\n",
        "    )\n",
        "\n",
        "    sweep_step_to_rfc = train_rfc_job.sweep(\n",
        "        compute=COMPUTE,\n",
        "        sampling_algorithm=SAMPLING_ALGORITHM,\n",
        "        primary_metric=METRIC,\n",
        "        goal=GOAL,\n",
        "    )\n",
        "\n",
        "    sweep_step_to_rfc.set_limits(max_total_trials=TOTAL_TRIALS, max_concurrent_trials=CONCURRENT_TRIALS, timeout=TIMEOUT)\n",
        "    sweep_step_to_rfc.early_termination = MedianStoppingPolicy(delay_evaluation=DELAY_EVALUATION, evaluation_interval=EVALUATION_INTERVAL)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211819674
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def train_svc_pipeline(\n",
        "    data_to_train,\n",
        "    data_to_test,\n",
        "    flag_remove_null_values,\n",
        "    learning_rate_to_train,\n",
        "    flag_remove_values_by_percentage,\n",
        "    percentage_to_remove_column,\n",
        "):\n",
        "\n",
        "    data_prep_job = data_prep_component(\n",
        "        data_to_train=data_to_train,\n",
        "        data_to_test=data_to_test,\n",
        "        flag_remove_null_values=flag_remove_null_values,\n",
        "        flag_remove_values_by_percentage=flag_remove_values_by_percentage,\n",
        "        percentage_to_remove_column=percentage_to_remove_column,\n",
        "    )\n",
        "\n",
        "    train_svc_job = train_svc(\n",
        "        train_data=data_prep_job.outputs.train_data,  # note: using outputs from previous step\n",
        "        test_data=data_prep_job.outputs.test_data,  # note: using outputs from previous step\n",
        "        kernel_to_svc=Choice(values=[\"linear\", \"rbf\", \"poly\", \"sigmoid\",\"precomputed\"]),\n",
        "        gamma_to_svc=Choice(values=[\"scale\", \"auto\"]),\n",
        "    )\n",
        "\n",
        "    sweep_step_to_svc = train_svc_job.sweep(\n",
        "        compute=COMPUTE,\n",
        "        sampling_algorithm=SAMPLING_ALGORITHM,\n",
        "        primary_metric=METRIC,\n",
        "        goal=GOAL,\n",
        "    )\n",
        "\n",
        "    sweep_step_to_svc.set_limits(max_total_trials=2*TOTAL_TRIALS, max_concurrent_trials=CONCURRENT_TRIALS, timeout=TIMEOUT_PLUS)\n",
        "    sweep_step_to_svc.early_termination = MedianStoppingPolicy(delay_evaluation=DELAY_EVALUATION, evaluation_interval=EVALUATION_INTERVAL)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211819768
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def train_xgb_pipeline(\n",
        "    data_to_train,\n",
        "    data_to_test,\n",
        "    flag_remove_null_values,\n",
        "    learning_rate_to_train,\n",
        "    flag_remove_values_by_percentage,\n",
        "    percentage_to_remove_column,\n",
        "):\n",
        "\n",
        "    data_prep_job = data_prep_component(\n",
        "        data_to_train=data_to_train,\n",
        "        data_to_test=data_to_test,\n",
        "        flag_remove_null_values=flag_remove_null_values,\n",
        "        flag_remove_values_by_percentage=flag_remove_values_by_percentage,\n",
        "        percentage_to_remove_column=percentage_to_remove_column,\n",
        "    )\n",
        "\n",
        "    train_xgb_job = train_xgb(\n",
        "        train_data=data_prep_job.outputs.train_data,  # note: using outputs from previous step\n",
        "        test_data=data_prep_job.outputs.test_data,  # note: using outputs from previous step\n",
        "        n_estimators_to_xgb=Choice(values=[100, 500, 1000]),\n",
        "        learning_rate_to_xgb=Uniform(min_value=0.01, max_value=0.3),\n",
        "    )\n",
        "\n",
        "    sweep_step_to_xgb = train_xgb_job.sweep(\n",
        "        compute=COMPUTE,\n",
        "        sampling_algorithm=SAMPLING_ALGORITHM,\n",
        "        primary_metric=METRIC,\n",
        "        goal=GOAL,\n",
        "    )\n",
        "\n",
        "    sweep_step_to_xgb.set_limits(max_total_trials=2*TOTAL_TRIALS, max_concurrent_trials=CONCURRENT_TRIALS, timeout=TIMEOUT)\n",
        "    sweep_step_to_xgb.early_termination = MedianStoppingPolicy(delay_evaluation=DELAY_EVALUATION, evaluation_interval=EVALUATION_INTERVAL)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211819854
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipelines = []\n",
        "\n",
        "for data_to_train, data_to_test in zip(arr_data_to_train, arr_data_to_test):\n",
        "\n",
        "    #pipelines.append(train_gbc_pipeline(\n",
        "    #    data_to_train=Input(type=\"uri_file\", path=data_to_train.path),\n",
        "    #    data_to_test=Input(type=\"uri_file\", path=data_to_test.path),\n",
        "    #    flag_remove_null_values=False,\n",
        "    #    flag_remove_values_by_percentage=False,\n",
        "    #    percentage_to_remove_column=0,\n",
        "    #))\n",
        "\n",
        "    #pipelines.append(train_nbc_pipeline(\n",
        "    #    data_to_train=Input(type=\"uri_file\", path=data_to_train.path),\n",
        "    #    data_to_test=Input(type=\"uri_file\", path=data_to_test.path),\n",
        "    #    flag_remove_null_values=False,\n",
        "    #    flag_remove_values_by_percentage=False,\n",
        "    #    percentage_to_remove_column=0,\n",
        "    #))\n",
        "\n",
        "    #pipelines.append(train_rfc_pipeline(\n",
        "    #    data_to_train=Input(type=\"uri_file\", path=data_to_train.path),\n",
        "    #    data_to_test=Input(type=\"uri_file\", path=data_to_test.path),\n",
        "    #    flag_remove_null_values=False,\n",
        "    #    flag_remove_values_by_percentage=False,\n",
        "    #    percentage_to_remove_column=0,\n",
        "    #))\n",
        "\n",
        "    pipelines.append(train_svc_pipeline(\n",
        "        data_to_train=Input(type=\"uri_file\", path=data_to_train.path),\n",
        "        data_to_test=Input(type=\"uri_file\", path=data_to_test.path),\n",
        "        flag_remove_null_values=False,\n",
        "        flag_remove_values_by_percentage=False,\n",
        "        percentage_to_remove_column=0,\n",
        "    ))\n",
        "\n",
        "    pipelines.append(train_xgb_pipeline(\n",
        "        data_to_train=Input(type=\"uri_file\", path=data_to_train.path),\n",
        "        data_to_test=Input(type=\"uri_file\", path=data_to_test.path),\n",
        "        flag_remove_null_values=False,\n",
        "        flag_remove_values_by_percentage=False,\n",
        "        percentage_to_remove_column=0,\n",
        "    ))\n",
        "\n",
        "print(pipelines)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[PipelineJob({'inputs': {'data_to_train': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304cc640>, 'data_to_test': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304cc1f0>, 'flag_remove_null_values': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304cc4c0>, 'flag_remove_values_by_percentage': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304cc280>, 'percentage_to_remove_column': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304ccb20>}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'DSL', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'train_rfc_pipeline', 'description': 'E2E data_perp-train pipeline', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': 'None', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f71304edfc0>, 'version': None, 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'train_rfc_pipeline', 'is_deterministic': None, 'inputs': {'data_to_train': {}, 'data_to_test': {}, 'flag_remove_null_values': {}, 'learning_rate_to_train': {}, 'flag_remove_values_by_percentage': {}, 'percentage_to_remove_column': {}}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': OrderedDict([('data_prep_job', Command({'parameters': {}, 'init': False, 'name': 'data_prep_job', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f713e202cb0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'data_to_train': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304ee7a0>, 'data_to_test': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304eeb90>, 'flag_remove_null_values': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304ec100>, 'flag_remove_values_by_percentage': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304ec670>, 'percentage_to_remove_column': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304ec2b0>}, 'job_outputs': {}, 'inputs': {'data_to_train': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f713e202da0>, 'data_to_test': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f713e2025f0>, 'flag_remove_null_values': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f713e202530>, 'flag_remove_values_by_percentage': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f713e203c70>, 'percentage_to_remove_column': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f713e202560>}, 'outputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f713e203a60>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f713e201de0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'data_prep_vrex_defaults_model', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/components/data_prep_vrex_defaults_model/versions/2024-05-08-23-43-30-2231322', 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml._restclient.v2022_10_01.models._models_py3.SystemData object at 0x7f71304a41f0>, 'serialize': <msrest.serialization.Serializer object at 0x7f71304a4820>, 'command': 'python data_prep.py  --data_to_train ${{inputs.data_to_train}}  --data_to_test ${{inputs.data_to_test}}  --flag_remove_null_values ${{inputs.flag_remove_null_values}} --flag_remove_values_by_percentage ${{inputs.flag_remove_values_by_percentage}} --percentage_to_remove_column ${{inputs.percentage_to_remove_column}} --train_data ${{outputs.train_data}} --test_data ${{outputs.test_data}}', 'code': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/codes/3dadffa3-a33d-4f77-a367-f4ba8758273e/versions/1', 'environment_variables': None, 'environment': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/environments/data-prep-dependencies/versions/v1', 'distribution': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'version': '2024-05-08-23-43-30-2231322', 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'Data Preparation Defaults Model', 'is_deterministic': True, 'inputs': {'data_to_train': {'type': 'uri_folder', 'optional': False}, 'data_to_test': {'type': 'uri_folder', 'optional': False}, 'flag_remove_null_values': {'type': 'boolean', 'optional': False}, 'flag_remove_values_by_percentage': {'type': 'boolean', 'optional': False}, 'percentage_to_remove_column': {'type': 'number', 'optional': False}}, 'outputs': {'train_data': {'type': 'uri_folder'}, 'test_data': {'type': 'uri_folder'}}, 'yaml_str': None, 'other_parameter': {}, 'additional_includes': [], 'CommandComponent__additional_includes_obj': None}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': 'd0655766-64a2-4876-b975-27d65370ca06', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'swept': False})), ('sweep_step_to_rfc', Sweep({'job_inputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f713e202d10>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f713203dde0>}, 'job_outputs': {'model': None}, 'init': False, 'name': 'sweep_step_to_rfc', 'type': 'sweep', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f713e202110>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': 'serverless', 'services': None, 'comment': None, 'inputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f713203f1f0>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f713203f070>, 'n_estimators_to_rfc': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f713203ebc0>}, 'outputs': {'model': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f713203fee0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'train_rfc_model', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/components/train_rfc_model/versions/2024-05-08-23-43-35-1402885', 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml._restclient.v2022_10_01.models._models_py3.SystemData object at 0x7f713203eda0>, 'serialize': <msrest.serialization.Serializer object at 0x7f713203ee60>, 'command': 'python train_rfc.py  --train_data ${{inputs.train_data}}  --test_data ${{inputs.test_data}}  --n_estimators_to_rfc ${{inputs.n_estimators_to_rfc}} --model ${{outputs.model}}\\n\\n\\n\\n  ', 'code': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/codes/8be1e8a2-1a04-4c5f-a6a6-42e487bc03fd/versions/1', 'environment_variables': None, 'environment': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/environments/train-dependencies/versions/v6', 'distribution': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'version': '2024-05-08-23-43-35-1402885', 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'Train Random Forest Classifier Model', 'is_deterministic': True, 'inputs': {'train_data': {'type': 'uri_folder', 'optional': False}, 'test_data': {'type': 'uri_folder', 'optional': False}, 'n_estimators_to_rfc': {'type': 'number', 'optional': False}}, 'outputs': {'model': {'type': 'uri_folder'}}, 'yaml_str': None, 'other_parameter': {}, 'additional_includes': [], 'CommandComponent__additional_includes_obj': None}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {}, 'instance_id': 'aa089914-d4b8-4c78-8f9a-9cbafeffb5da', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'sampling_algorithm': 'bayesian', 'early_termination': <azure.ai.ml.entities._job.sweep.early_termination_policy.MedianStoppingPolicy object at 0x7f713203f130>, 'limits': <azure.ai.ml.entities._job.job_limits.SweepJobLimits object at 0x7f713203eb60>, 'search_space': {'n_estimators_to_rfc': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f71619d9c60>}, 'queue_settings': None, 'objective': <azure.ai.ml.entities._job.sweep.objective.Objective object at 0x7f71304eefe0>, 'identity': None}))]), 'job_types': {'command': 1, 'sweep': 1}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 2}, 'source_job_id': None}), 'type': 'pipeline', 'status': None, 'log_files': None, 'name': None, 'description': 'E2E data_perp-train pipeline', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f71304cc550>, 'display_name': 'train_rfc_pipeline', 'experiment_name': None, 'compute': 'serverless', 'services': None, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None}), PipelineJob({'inputs': {'data_to_train': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f713064f1f0>, 'data_to_test': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f713064c910>, 'flag_remove_null_values': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f713064d6f0>, 'flag_remove_values_by_percentage': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f713064ca60>, 'percentage_to_remove_column': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f713064da20>}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'DSL', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'train_svc_pipeline', 'description': 'E2E data_perp-train pipeline', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': 'None', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f71304a5c60>, 'version': None, 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'train_svc_pipeline', 'is_deterministic': None, 'inputs': {'data_to_train': {}, 'data_to_test': {}, 'flag_remove_null_values': {}, 'learning_rate_to_train': {}, 'flag_remove_values_by_percentage': {}, 'percentage_to_remove_column': {}}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': OrderedDict([('data_prep_job', Command({'parameters': {}, 'init': False, 'name': 'data_prep_job', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f71304a77f0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'data_to_train': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304a54b0>, 'data_to_test': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304a59c0>, 'flag_remove_null_values': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304a5c30>, 'flag_remove_values_by_percentage': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304a49a0>, 'percentage_to_remove_column': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304a6e90>}, 'job_outputs': {}, 'inputs': {'data_to_train': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a6f20>, 'data_to_test': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a65c0>, 'flag_remove_null_values': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a6890>, 'flag_remove_values_by_percentage': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a6530>, 'percentage_to_remove_column': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a6b30>}, 'outputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f71304a5f90>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f71304a66b0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'data_prep_vrex_defaults_model', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/components/data_prep_vrex_defaults_model/versions/2024-05-08-23-43-30-2231322', 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml._restclient.v2022_10_01.models._models_py3.SystemData object at 0x7f71304a41f0>, 'serialize': <msrest.serialization.Serializer object at 0x7f71304a4820>, 'command': 'python data_prep.py  --data_to_train ${{inputs.data_to_train}}  --data_to_test ${{inputs.data_to_test}}  --flag_remove_null_values ${{inputs.flag_remove_null_values}} --flag_remove_values_by_percentage ${{inputs.flag_remove_values_by_percentage}} --percentage_to_remove_column ${{inputs.percentage_to_remove_column}} --train_data ${{outputs.train_data}} --test_data ${{outputs.test_data}}', 'code': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/codes/3dadffa3-a33d-4f77-a367-f4ba8758273e/versions/1', 'environment_variables': None, 'environment': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/environments/data-prep-dependencies/versions/v1', 'distribution': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'version': '2024-05-08-23-43-30-2231322', 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'Data Preparation Defaults Model', 'is_deterministic': True, 'inputs': {'data_to_train': {'type': 'uri_folder', 'optional': False}, 'data_to_test': {'type': 'uri_folder', 'optional': False}, 'flag_remove_null_values': {'type': 'boolean', 'optional': False}, 'flag_remove_values_by_percentage': {'type': 'boolean', 'optional': False}, 'percentage_to_remove_column': {'type': 'number', 'optional': False}}, 'outputs': {'train_data': {'type': 'uri_folder'}, 'test_data': {'type': 'uri_folder'}}, 'yaml_str': None, 'other_parameter': {}, 'additional_includes': [], 'CommandComponent__additional_includes_obj': None}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '82ba24af-8796-4d9d-bb2c-1027222823cf', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'swept': False})), ('sweep_step_to_svc', Sweep({'job_inputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f71304a4310>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f71304a4340>}, 'job_outputs': {'model': None}, 'init': False, 'name': 'sweep_step_to_svc', 'type': 'sweep', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f71304a60e0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': 'serverless', 'services': None, 'comment': None, 'inputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a6440>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a43a0>, 'kernel_to_svc': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a4370>, 'gamma_to_svc': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a6f80>}, 'outputs': {'model': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f713064c550>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'train_svc_model', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/components/train_svc_model/versions/2024-05-08-23-43-36-5992663', 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml._restclient.v2022_10_01.models._models_py3.SystemData object at 0x7f71304a4dc0>, 'serialize': <msrest.serialization.Serializer object at 0x7f71304a6080>, 'command': 'python train_svc.py  --train_data ${{inputs.train_data}}  --test_data ${{inputs.test_data}}  --kernel_to_svc ${{inputs.kernel_to_svc}} --gamma_to_svc ${{inputs.gamma_to_svc}} --model ${{outputs.model}}\\n\\n\\n\\n  ', 'code': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/codes/8be1e8a2-1a04-4c5f-a6a6-42e487bc03fd/versions/1', 'environment_variables': None, 'environment': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/environments/train-dependencies/versions/v6', 'distribution': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'version': '2024-05-08-23-43-36-5992663', 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'Train Support Vector Classification Model', 'is_deterministic': True, 'inputs': {'train_data': {'type': 'uri_folder', 'optional': False}, 'test_data': {'type': 'uri_folder', 'optional': False}, 'kernel_to_svc': {'type': 'string', 'optional': False}, 'gamma_to_svc': {'type': 'string', 'optional': False}}, 'outputs': {'model': {'type': 'uri_folder'}}, 'yaml_str': None, 'other_parameter': {}, 'additional_includes': [], 'CommandComponent__additional_includes_obj': None}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {}, 'instance_id': '123e2218-8618-4a47-92f1-7a9aa2001558', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'sampling_algorithm': 'bayesian', 'early_termination': <azure.ai.ml.entities._job.sweep.early_termination_policy.MedianStoppingPolicy object at 0x7f713064c3d0>, 'limits': <azure.ai.ml.entities._job.job_limits.SweepJobLimits object at 0x7f713064e140>, 'search_space': {'kernel_to_svc': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f71304cc250>, 'gamma_to_svc': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f71304a5900>}, 'queue_settings': None, 'objective': <azure.ai.ml.entities._job.sweep.objective.Objective object at 0x7f71304a5fc0>, 'identity': None}))]), 'job_types': {'command': 1, 'sweep': 1}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 2}, 'source_job_id': None}), 'type': 'pipeline', 'status': None, 'log_files': None, 'name': None, 'description': 'E2E data_perp-train pipeline', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f713064c2e0>, 'display_name': 'train_svc_pipeline', 'experiment_name': None, 'compute': 'serverless', 'services': None, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None}), PipelineJob({'inputs': {'data_to_train': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304cfd00>, 'data_to_test': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304cdff0>, 'flag_remove_null_values': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304cdc60>, 'flag_remove_values_by_percentage': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304cdc30>, 'percentage_to_remove_column': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f71304ce320>}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'DSL', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'train_xgb_pipeline', 'description': 'E2E data_perp-train pipeline', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': 'None', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f71304cd4e0>, 'version': None, 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'train_xgb_pipeline', 'is_deterministic': None, 'inputs': {'data_to_train': {}, 'data_to_test': {}, 'flag_remove_null_values': {}, 'learning_rate_to_train': {}, 'flag_remove_values_by_percentage': {}, 'percentage_to_remove_column': {}}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': OrderedDict([('data_prep_job', Command({'parameters': {}, 'init': False, 'name': 'data_prep_job', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f71304a7280>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'data_to_train': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f713064c490>, 'data_to_test': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f713064d9c0>, 'flag_remove_null_values': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f713064d990>, 'flag_remove_values_by_percentage': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f713064dae0>, 'percentage_to_remove_column': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f713064e980>}, 'job_outputs': {}, 'inputs': {'data_to_train': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a74c0>, 'data_to_test': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a7b20>, 'flag_remove_null_values': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a7d00>, 'flag_remove_values_by_percentage': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a6dd0>, 'percentage_to_remove_column': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304a55a0>}, 'outputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f71304a7c40>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f71304a7580>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'data_prep_vrex_defaults_model', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/components/data_prep_vrex_defaults_model/versions/2024-05-08-23-43-30-2231322', 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml._restclient.v2022_10_01.models._models_py3.SystemData object at 0x7f71304a41f0>, 'serialize': <msrest.serialization.Serializer object at 0x7f71304a4820>, 'command': 'python data_prep.py  --data_to_train ${{inputs.data_to_train}}  --data_to_test ${{inputs.data_to_test}}  --flag_remove_null_values ${{inputs.flag_remove_null_values}} --flag_remove_values_by_percentage ${{inputs.flag_remove_values_by_percentage}} --percentage_to_remove_column ${{inputs.percentage_to_remove_column}} --train_data ${{outputs.train_data}} --test_data ${{outputs.test_data}}', 'code': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/codes/3dadffa3-a33d-4f77-a367-f4ba8758273e/versions/1', 'environment_variables': None, 'environment': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/environments/data-prep-dependencies/versions/v1', 'distribution': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'version': '2024-05-08-23-43-30-2231322', 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'Data Preparation Defaults Model', 'is_deterministic': True, 'inputs': {'data_to_train': {'type': 'uri_folder', 'optional': False}, 'data_to_test': {'type': 'uri_folder', 'optional': False}, 'flag_remove_null_values': {'type': 'boolean', 'optional': False}, 'flag_remove_values_by_percentage': {'type': 'boolean', 'optional': False}, 'percentage_to_remove_column': {'type': 'number', 'optional': False}}, 'outputs': {'train_data': {'type': 'uri_folder'}, 'test_data': {'type': 'uri_folder'}}, 'yaml_str': None, 'other_parameter': {}, 'additional_includes': [], 'CommandComponent__additional_includes_obj': None}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '74ddcc8b-ad9d-4c11-8237-9b241002e5ff', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'swept': False})), ('sweep_step_to_xgb', Sweep({'job_inputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f71304a7eb0>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f71304cdcc0>}, 'job_outputs': {'model': None}, 'init': False, 'name': 'sweep_step_to_xgb', 'type': 'sweep', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f71304a7d30>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': 'serverless', 'services': None, 'comment': None, 'inputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304cfd30>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304cdc90>, 'n_estimators_to_xgb': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304ce3b0>, 'learning_rate_to_xgb': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f71304cdd50>}, 'outputs': {'model': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f71304ce020>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'train_xgb_model', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/components/train_xgb_model/versions/2024-05-08-23-43-38-2536869', 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml._restclient.v2022_10_01.models._models_py3.SystemData object at 0x7f713e202230>, 'serialize': <msrest.serialization.Serializer object at 0x7f713e202d40>, 'command': 'python train_xgb.py  --train_data ${{inputs.train_data}}  --test_data ${{inputs.test_data}}  --n_estimators_to_xgb ${{inputs.n_estimators_to_xgb}} --learning_rate_to_xgb ${{inputs.learning_rate_to_xgb}} --model ${{outputs.model}}\\n\\n\\n\\n  ', 'code': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/codes/8be1e8a2-1a04-4c5f-a6a6-42e487bc03fd/versions/1', 'environment_variables': None, 'environment': '/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/environments/train-dependencies/versions/v6', 'distribution': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'version': '2024-05-08-23-43-38-2536869', 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'Train XGBoosting Classifier Model', 'is_deterministic': True, 'inputs': {'train_data': {'type': 'uri_folder', 'optional': False}, 'test_data': {'type': 'uri_folder', 'optional': False}, 'n_estimators_to_xgb': {'type': 'number', 'optional': False}, 'learning_rate_to_xgb': {'type': 'number', 'optional': False}}, 'outputs': {'model': {'type': 'uri_folder'}}, 'yaml_str': None, 'other_parameter': {}, 'additional_includes': [], 'CommandComponent__additional_includes_obj': None}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {}, 'instance_id': '50be878f-c145-4aa7-a406-e8338a01ee74', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'sampling_algorithm': 'bayesian', 'early_termination': <azure.ai.ml.entities._job.sweep.early_termination_policy.MedianStoppingPolicy object at 0x7f71304cf520>, 'limits': <azure.ai.ml.entities._job.job_limits.SweepJobLimits object at 0x7f71304cf7c0>, 'search_space': {'n_estimators_to_xgb': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f713e203d30>, 'learning_rate_to_xgb': <azure.ai.ml.entities._job.sweep.search_space.Uniform object at 0x7f713e203f40>}, 'queue_settings': None, 'objective': <azure.ai.ml.entities._job.sweep.objective.Objective object at 0x7f71304a7ee0>, 'identity': None}))]), 'job_types': {'command': 1, 'sweep': 1}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 2}, 'source_job_id': None}), 'type': 'pipeline', 'status': None, 'log_files': None, 'name': None, 'description': 'E2E data_perp-train pipeline', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/comp-standard-e4ds-v4/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f71304ce290>, 'display_name': 'train_xgb_pipeline', 'experiment_name': None, 'compute': 'serverless', 'services': None, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})]\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211819959
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "\n",
        "models = ['svc', 'xgb']\n",
        "\n",
        "def _get_experiment_names() -> [str]:\n",
        "    experiment_names = []\n",
        "    for train_name, test_name in zip(TRAIN_DATAS, TEST_DATAS):\n",
        "        for model_name in models:\n",
        "            current_time = dt.datetime.now()\n",
        "            formatted_time = current_time.strftime(\"%Y_%m_%d_%H_%M_%S\")  # Formata a data e hora atual\n",
        "            train_name_base = train_name.split('.')[0]\n",
        "            test_name_base = test_name.split('.')[0]\n",
        "            name = f\"{train_name_base}_tested_{test_name_base}_model_{model_name}\"\n",
        "            experiment_names.append(name)\n",
        "            print(name)\n",
        "    return experiment_names\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211820060
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_names = _get_experiment_names()\n",
        "for pipeline, experiment_name in zip(pipelines, experiment_names):\n",
        "    print(experiment_name)\n",
        "    print(pipeline)\n",
        "    pipeline_job = ml_client.jobs.create_or_update(\n",
        "        pipeline,\n",
        "        experiment_name=experiment_name,\n",
        "    )\n",
        "\n",
        "    ml_client.jobs.stream(pipeline_job.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "vrex_consolidated_2008_2017_tested_vrex_consolidated_2018_2021_model_rfc\nvrex_consolidated_2008_2017_tested_vrex_consolidated_2018_2021_model_svc\nvrex_consolidated_2008_2017_tested_vrex_consolidated_2018_2021_model_xgb\nvrex_consolidated_2008_2017_tested_vrex_consolidated_2018_2021_model_rfc\ndisplay_name: train_rfc_pipeline\ndescription: E2E data_perp-train pipeline\ntype: pipeline\ninputs:\n  data_to_train:\n    type: uri_file\n    path: azureml://subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourcegroups/luiz.victor.dev-rg/workspaces/tcc-experiments/datastores/workspaceblobstore/paths/LocalUpload/4722af391476dd8597905df3c3ae6d19/vrex_consolidated_2008_2017.csv\n  data_to_test:\n    type: uri_file\n    path: azureml://subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourcegroups/luiz.victor.dev-rg/workspaces/tcc-experiments/datastores/workspaceblobstore/paths/LocalUpload/154dc9171c762e1cab20b8998d7d1c63/vrex_consolidated_2018_2021.csv\n  flag_remove_null_values: 0\n  flag_remove_values_by_percentage: 0\n  percentage_to_remove_column: 0\njobs:\n  data_prep_job:\n    type: command\n    inputs:\n      data_to_train:\n        path: ${{parent.inputs.data_to_train}}\n      data_to_test:\n        path: ${{parent.inputs.data_to_test}}\n      flag_remove_null_values:\n        path: ${{parent.inputs.flag_remove_null_values}}\n      flag_remove_values_by_percentage:\n        path: ${{parent.inputs.flag_remove_values_by_percentage}}\n      percentage_to_remove_column:\n        path: ${{parent.inputs.percentage_to_remove_column}}\n    resources:\n      instance_count: 1\n    component:\n      name: data_prep_vrex_defaults_model\n      version: 2024-05-08-23-43-30-2231322\n      display_name: Data Preparation Defaults Model\n      type: command\n      inputs:\n        data_to_train:\n          type: uri_folder\n          optional: false\n        data_to_test:\n          type: uri_folder\n          optional: false\n        flag_remove_null_values:\n          type: boolean\n          optional: false\n        flag_remove_values_by_percentage:\n          type: boolean\n          optional: false\n        percentage_to_remove_column:\n          type: number\n          optional: false\n      outputs:\n        train_data:\n          type: uri_folder\n        test_data:\n          type: uri_folder\n      command: python data_prep.py  --data_to_train ${{inputs.data_to_train}}  --data_to_test\n        ${{inputs.data_to_test}}  --flag_remove_null_values ${{inputs.flag_remove_null_values}}\n        --flag_remove_values_by_percentage ${{inputs.flag_remove_values_by_percentage}}\n        --percentage_to_remove_column ${{inputs.percentage_to_remove_column}} --train_data\n        ${{outputs.train_data}} --test_data ${{outputs.test_data}}\n      environment: azureml:/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/environments/data-prep-dependencies/versions/v1\n      code: azureml:/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/codes/3dadffa3-a33d-4f77-a367-f4ba8758273e/versions/1\n      resources:\n        instance_count: 1\n      creation_context:\n        created_at: '2024-05-08T23:43:31.067699+00:00'\n        created_by: Luiz Victor Ferreira Santos\n        created_by_type: User\n        last_modified_at: '2024-05-08T23:43:31.159442+00:00'\n        last_modified_by: Luiz Victor Ferreira Santos\n        last_modified_by_type: User\n      id: /subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/components/data_prep_vrex_defaults_model/versions/2024-05-08-23-43-30-2231322\n      is_deterministic: true\n  sweep_step_to_rfc:\n    type: sweep\n    inputs:\n      train_data:\n        path: ${{parent.jobs.data_prep_job.outputs.train_data}}\n      test_data:\n        path: ${{parent.jobs.data_prep_job.outputs.test_data}}\n    limits:\n      max_concurrent_trials: 10\n      max_total_trials: 20\n      timeout: 3600\n    objective:\n      goal: maximize\n      primary_metric: training_accuracy_score\n    compute: azureml:serverless\n    sampling_algorithm: bayesian\n    search_space:\n      n_estimators_to_rfc:\n        values:\n        - 50\n        - 100\n        - 200\n        type: choice\n    early_termination:\n      evaluation_interval: 1\n      delay_evaluation: 5\n      type: median_stopping\n    trial:\n      name: train_rfc_model\n      version: 2024-05-08-23-43-35-1402885\n      display_name: Train Random Forest Classifier Model\n      type: command\n      inputs:\n        train_data:\n          type: uri_folder\n          optional: false\n        test_data:\n          type: uri_folder\n          optional: false\n        n_estimators_to_rfc:\n          type: number\n          optional: false\n      outputs:\n        model:\n          type: uri_folder\n      command: \"python train_rfc.py  --train_data ${{inputs.train_data}}  --test_data\\\n        \\ ${{inputs.test_data}}  --n_estimators_to_rfc ${{inputs.n_estimators_to_rfc}}\\\n        \\ --model ${{outputs.model}}\\n\\n\\n\\n  \"\n      environment: azureml:/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/environments/train-dependencies/versions/v6\n      code: azureml:/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/codes/8be1e8a2-1a04-4c5f-a6a6-42e487bc03fd/versions/1\n      resources:\n        instance_count: 1\n      creation_context:\n        created_at: '2024-05-08T23:43:35.711813+00:00'\n        created_by: Luiz Victor Ferreira Santos\n        created_by_type: User\n        last_modified_at: '2024-05-08T23:43:35.783170+00:00'\n        last_modified_by: Luiz Victor Ferreira Santos\n        last_modified_by_type: User\n      id: /subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourceGroups/luiz.victor.dev-rg/providers/Microsoft.MachineLearningServices/workspaces/tcc-experiments/components/train_rfc_model/versions/2024-05-08-23-43-35-1402885\n      is_deterministic: true\ncompute: azureml:serverless\n\nRunId: nifty_pump_mwgd9yghlb\nWeb View: https://ml.azure.com/runs/nifty_pump_mwgd9yghlb?wsid=/subscriptions/a3f56f48-3efb-4970-81a3-e4eda598333c/resourcegroups/luiz.victor.dev-rg/workspaces/tcc-experiments\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-05-08 23:43:45Z] Submitting 1 runs, first five are: e58811c9:2caae2ab-4f49-49c2-8a9c-03967adc720a\n[2024-05-08 23:43:47Z] Completing processing run id 2caae2ab-4f49-49c2-8a9c-03967adc720a.\n[2024-05-08 23:43:47Z] Submitting 1 runs, first five are: e86c2921:dacc60f0-59fb-4211-9769-05f6a27c55fa\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715211858123
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}