{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1716433429163
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# authenticate\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "SUBSCRIPTION=\"da6ec459-95c4-4f18-8440-d275df8d38b7\"\n",
        "RESOURCE_GROUP=\"tcc-exp-rg\"\n",
        "WS_NAME=\"tcc-experiments\"\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=SUBSCRIPTION,\n",
        "    resource_group_name=RESOURCE_GROUP,\n",
        "    workspace_name=WS_NAME,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1716433429381
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eastus2 : tcc-exp-rg\n"
          ]
        }
      ],
      "source": [
        "# Verify that the handle works correctly.  \n",
        "# If you ge an error here, modify your SUBSCRIPTION, RESOURCE_GROUP, and WS_NAME in the previous cell.\n",
        "ws = ml_client.workspaces.get(WS_NAME)\n",
        "print(ws.location,\":\", ws.resource_group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1716433429673
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data to train asset URI: azureml://subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments/datastores/workspaceblobstore/paths/LocalUpload/56e8c2a8ab41500c2c35e5072b17e8b7/vrex_encoded_tf_idf_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_.csv - name: vrex_encoded_tf_idf_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_\n",
            "Data to test asset URI: azureml://subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments/datastores/workspaceblobstore/paths/LocalUpload/767c68907ee7896489103545b8b84a99/vrex_encoded_tf_idf_2018_2019_2020_2021_.csv - name: vrex_encoded_tf_idf_2018_2019_2020_2021_\n"
          ]
        }
      ],
      "source": [
        "TRAIN_DATAS = [\n",
        "    \"vrex_encoded_tf_idf_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017.csv\"\n",
        "]\n",
        "\n",
        "TEST_DATAS = [\n",
        "    \"vrex_encoded_tf_idf_2018_2019_2020_2021.csv\"\n",
        "]\n",
        "\n",
        "version = \"v1\"\n",
        "\n",
        "arr_data_to_train = []\n",
        "arr_data_to_test = []\n",
        "\n",
        "for to_train, to_test in zip(TRAIN_DATAS, TEST_DATAS):\n",
        "    data_to_train = ml_client.data.get(name=to_train.split(\".\")[0], version=version)\n",
        "    arr_data_to_train.append(data_to_train)\n",
        "    print(f\"Data to train asset URI: {data_to_train.path} - name: {to_train.split('.')[0]}\")\n",
        "\n",
        "    data_to_test = ml_client.data.get(name=to_test.split('.')[0], version=version)\n",
        "    arr_data_to_test.append(data_to_test)\n",
        "    print(f\"Data to test asset URI: {data_to_test.path} - name: {to_test.split('.')[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1716433432138
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component data_prep_vrex_defaults_model with Version 2024-05-23-03-03-50-6535894 is registered\n"
          ]
        }
      ],
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "data_prep_component = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/preparation/data_prep.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "data_prep_component = ml_client.create_or_update(data_prep_component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {data_prep_component.name} with Version {data_prep_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "infogain_component = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/feature_selection/infogain.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "infogain_component = ml_client.create_or_update(infogain_component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {infogain_component.name} with Version {infogain_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "gini_component = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/feature_selection/gini.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "gini_component = ml_client.create_or_update(gini_component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {gini_component.name} with Version {gini_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1716433433881
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component train_gbc_model with Version 2024-05-23-03-03-52-8698708 is registered\n"
          ]
        }
      ],
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_gbc = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/train/train_gbc.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "train_gbc = ml_client.create_or_update(train_gbc)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_gbc.name} with Version {train_gbc.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1716433435332
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component train_nbc_model with Version 2024-05-23-03-03-54-4209072 is registered\n"
          ]
        }
      ],
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_nbc = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/train/train_nbc.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "train_nbc = ml_client.create_or_update(train_nbc)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_nbc.name} with Version {train_nbc.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1716433437217
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component train_rfc_model with Version 2024-05-23-03-03-55-9222179 is registered\n"
          ]
        }
      ],
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_rfc = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/train/train_rfc.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "train_rfc = ml_client.create_or_update(train_rfc)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_rfc.name} with Version {train_rfc.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1716433438911
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component train_svc_model with Version 2024-05-23-03-03-57-6669277 is registered\n"
          ]
        }
      ],
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_svc = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/train/train_svc.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "train_svc = ml_client.create_or_update(train_svc)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_svc.name} with Version {train_svc.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1716433440351
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component train_xgb_model with Version 2024-05-23-03-03-59-3882240 is registered\n"
          ]
        }
      ],
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_xgb = load_component(source=\"/home/azureuser/cloudfiles/code/Users/luiz.victor.dev/tcc_experiments_az_ml/src/components/train/train_xgb.yaml\")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "train_xgb = ml_client.create_or_update(train_xgb)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_xgb.name} with Version {train_xgb.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1716433440450
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "TOTAL_TRIALS = 20\n",
        "CONCURRENT_TRIALS = 10\n",
        "TIMEOUT = 2*3600\n",
        "TIMEOUT_PLUS = 2*7200\n",
        "\n",
        "COMPUTE = 'serverless'\n",
        "SAMPLING_ALGORITHM = 'bayesian'\n",
        "METRIC = 'training_accuracy_score'\n",
        "GOAL = 'Maximize'\n",
        "EVALUATION_INTERVAL = 1\n",
        "DELAY_EVALUATION = 5\n",
        "\n",
        "# the dsl decorator tells the sdk that we are defining an Azure Machine Learning pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1716433440554
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def train_gbc_pipeline(\n",
        "    data_to_train,\n",
        "    data_to_test,\n",
        "    flag_remove_null_values,\n",
        "    flag_remove_values_by_percentage,\n",
        "    percentage_to_remove_column,\n",
        "):\n",
        "\n",
        "    data_prep_job = data_prep_component(\n",
        "        data_to_train=data_to_train,\n",
        "        data_to_test=data_to_test,\n",
        "        flag_remove_null_values=flag_remove_null_values,\n",
        "        flag_remove_values_by_percentage=flag_remove_values_by_percentage,\n",
        "        percentage_to_remove_column=percentage_to_remove_column,\n",
        "    )\n",
        "\n",
        "    infogain_job = infogain_component(\n",
        "        data_to_train=data_prep_job.outputs.train_data,\n",
        "        data_to_test=data_prep_job.outputs.test_data,\n",
        "        feature_quantity=0.5,\n",
        "    )\n",
        "\n",
        "    train_gbc_job = train_gbc(\n",
        "        train_data=infogain_job.outputs.train_data_feat_sel,  \n",
        "        test_data=infogain_job.outputs.test_data_feat_sel,  \n",
        "        n_estimators_to_gbc=Choice(values=[50, 100, 200]),\n",
        "        learning_rate_to_gbc=Uniform(min_value=0.01, max_value=0.3),\n",
        "    )\n",
        "\n",
        "    sweep_step_to_gbc = train_gbc_job.sweep(\n",
        "        compute=COMPUTE,\n",
        "        sampling_algorithm=SAMPLING_ALGORITHM,\n",
        "        primary_metric=METRIC,\n",
        "        goal=GOAL,\n",
        "    )\n",
        "\n",
        "    sweep_step_to_gbc.set_limits(max_total_trials=2*TOTAL_TRIALS, max_concurrent_trials=CONCURRENT_TRIALS, timeout=TIMEOUT)\n",
        "\n",
        "    sweep_step_to_gbc.early_termination = MedianStoppingPolicy(delay_evaluation=DELAY_EVALUATION, evaluation_interval=EVALUATION_INTERVAL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1716433440649
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def train_nbc_pipeline(\n",
        "    data_to_train,\n",
        "    data_to_test,\n",
        "    flag_remove_null_values,\n",
        "    flag_remove_values_by_percentage,\n",
        "    percentage_to_remove_column,\n",
        "):\n",
        "\n",
        "    data_prep_job = data_prep_component(\n",
        "        data_to_train=data_to_train,\n",
        "        data_to_test=data_to_test,\n",
        "        flag_remove_null_values=flag_remove_null_values,\n",
        "        flag_remove_values_by_percentage=flag_remove_values_by_percentage,\n",
        "        percentage_to_remove_column=percentage_to_remove_column,\n",
        "    )\n",
        "\n",
        "    train_nbc_job = train_nbc(\n",
        "        train_data=data_prep_job.outputs.train_data,  \n",
        "        test_data=data_prep_job.outputs.test_data,  \n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1716433440739
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def train_rfc_pipeline(\n",
        "    data_to_train,\n",
        "    data_to_test,\n",
        "    flag_remove_null_values,\n",
        "    learning_rate_to_train,\n",
        "    flag_remove_values_by_percentage,\n",
        "    percentage_to_remove_column,\n",
        "):\n",
        "\n",
        "    data_prep_job = data_prep_component(\n",
        "        data_to_train=data_to_train,\n",
        "        data_to_test=data_to_test,\n",
        "        flag_remove_null_values=flag_remove_null_values,\n",
        "        flag_remove_values_by_percentage=flag_remove_values_by_percentage,\n",
        "        percentage_to_remove_column=percentage_to_remove_column,\n",
        "    )\n",
        "\n",
        "    train_rfc_job = train_rfc(\n",
        "        train_data=data_prep_job.outputs.train_data,  \n",
        "        test_data=data_prep_job.outputs.test_data,  \n",
        "        n_estimators_to_rfc=Choice(values=[50, 100, 200]),\n",
        "    )\n",
        "\n",
        "    sweep_step_to_rfc = train_rfc_job.sweep(\n",
        "        compute=COMPUTE,\n",
        "        sampling_algorithm=SAMPLING_ALGORITHM,\n",
        "        primary_metric=METRIC,\n",
        "        goal=GOAL,\n",
        "    )\n",
        "\n",
        "    sweep_step_to_rfc.set_limits(max_total_trials=TOTAL_TRIALS, max_concurrent_trials=CONCURRENT_TRIALS, timeout=TIMEOUT)\n",
        "    sweep_step_to_rfc.early_termination = MedianStoppingPolicy(delay_evaluation=DELAY_EVALUATION, evaluation_interval=EVALUATION_INTERVAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1716433440831
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def train_svc_pipeline(\n",
        "    data_to_train,\n",
        "    data_to_test,\n",
        "    flag_remove_null_values,\n",
        "    learning_rate_to_train,\n",
        "    flag_remove_values_by_percentage,\n",
        "    percentage_to_remove_column,\n",
        "):\n",
        "\n",
        "    data_prep_job = data_prep_component(\n",
        "        data_to_train=data_to_train,\n",
        "        data_to_test=data_to_test,\n",
        "        flag_remove_null_values=flag_remove_null_values,\n",
        "        flag_remove_values_by_percentage=flag_remove_values_by_percentage,\n",
        "        percentage_to_remove_column=percentage_to_remove_column,\n",
        "    )\n",
        "\n",
        "    train_svc_job = train_svc(\n",
        "        train_data=data_prep_job.outputs.train_data,  \n",
        "        test_data=data_prep_job.outputs.test_data,  \n",
        "        kernel_to_svc=Choice(values=[\"linear\", \"rbf\", \"poly\", \"sigmoid\",\"precomputed\"]),\n",
        "        gamma_to_svc=Choice(values=[\"scale\", \"auto\"]),\n",
        "    )\n",
        "\n",
        "    sweep_step_to_svc = train_svc_job.sweep(\n",
        "        compute=COMPUTE,\n",
        "        sampling_algorithm=SAMPLING_ALGORITHM,\n",
        "        primary_metric=METRIC,\n",
        "        goal=GOAL,\n",
        "    )\n",
        "\n",
        "    sweep_step_to_svc.set_limits(max_total_trials=2*TOTAL_TRIALS, max_concurrent_trials=CONCURRENT_TRIALS, timeout=TIMEOUT_PLUS)\n",
        "    sweep_step_to_svc.early_termination = MedianStoppingPolicy(delay_evaluation=DELAY_EVALUATION, evaluation_interval=EVALUATION_INTERVAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1716433440916
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def train_xgb_pipeline(\n",
        "    data_to_train,\n",
        "    data_to_test,\n",
        "    flag_remove_null_values,\n",
        "    learning_rate_to_train,\n",
        "    flag_remove_values_by_percentage,\n",
        "    percentage_to_remove_column,\n",
        "):\n",
        "\n",
        "    data_prep_job = data_prep_component(\n",
        "        data_to_train=data_to_train,\n",
        "        data_to_test=data_to_test,\n",
        "        flag_remove_null_values=flag_remove_null_values,\n",
        "        flag_remove_values_by_percentage=flag_remove_values_by_percentage,\n",
        "        percentage_to_remove_column=percentage_to_remove_column,\n",
        "    )\n",
        "\n",
        "    train_xgb_job = train_xgb(\n",
        "        train_data=data_prep_job.outputs.train_data,  \n",
        "        test_data=data_prep_job.outputs.test_data,  \n",
        "        n_estimators_to_xgb=Choice(values=[100, 500, 1000]),\n",
        "        learning_rate_to_xgb=Uniform(min_value=0.01, max_value=0.3),\n",
        "    )\n",
        "\n",
        "    sweep_step_to_xgb = train_xgb_job.sweep(\n",
        "        compute=COMPUTE,\n",
        "        sampling_algorithm=SAMPLING_ALGORITHM,\n",
        "        primary_metric=METRIC,\n",
        "        goal=GOAL,\n",
        "    )\n",
        "\n",
        "    sweep_step_to_xgb.set_limits(max_total_trials=2*TOTAL_TRIALS, max_concurrent_trials=CONCURRENT_TRIALS, timeout=TIMEOUT_PLUS)\n",
        "    sweep_step_to_xgb.early_termination = MedianStoppingPolicy(delay_evaluation=DELAY_EVALUATION, evaluation_interval=EVALUATION_INTERVAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1716433441082
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "pipelines = []\n",
        "\n",
        "for data_to_train, data_to_test in zip(arr_data_to_train, arr_data_to_test):\n",
        "\n",
        "    pipelines.append(train_nbc_pipeline(\n",
        "        data_to_train=Input(type=\"uri_file\", path=data_to_train.path),\n",
        "        data_to_test=Input(type=\"uri_file\", path=data_to_test.path),\n",
        "        flag_remove_null_values=False,\n",
        "        flag_remove_values_by_percentage=False,\n",
        "        percentage_to_remove_column=0,\n",
        "    ))\n",
        "\n",
        "    pipelines.append(train_gbc_pipeline(\n",
        "        data_to_train=Input(type=\"uri_file\", path=data_to_train.path),\n",
        "        data_to_test=Input(type=\"uri_file\", path=data_to_test.path),\n",
        "        flag_remove_null_values=False,\n",
        "        flag_remove_values_by_percentage=False,\n",
        "        percentage_to_remove_column=0,\n",
        "    ))\n",
        "\n",
        "    pipelines.append(train_rfc_pipeline(\n",
        "        data_to_train=Input(type=\"uri_file\", path=data_to_train.path),\n",
        "        data_to_test=Input(type=\"uri_file\", path=data_to_test.path),\n",
        "        flag_remove_null_values=False,\n",
        "        flag_remove_values_by_percentage=False,\n",
        "        percentage_to_remove_column=0,\n",
        "    ))\n",
        "\n",
        "    pipelines.append(train_svc_pipeline(\n",
        "        data_to_train=Input(type=\"uri_file\", path=data_to_train.path),\n",
        "        data_to_test=Input(type=\"uri_file\", path=data_to_test.path),\n",
        "        flag_remove_null_values=False,\n",
        "        flag_remove_values_by_percentage=False,\n",
        "        percentage_to_remove_column=0,\n",
        "    ))\n",
        "\n",
        "    pipelines.append(train_xgb_pipeline(\n",
        "        data_to_train=Input(type=\"uri_file\", path=data_to_train.path),\n",
        "        data_to_test=Input(type=\"uri_file\", path=data_to_test.path),\n",
        "        flag_remove_null_values=False,\n",
        "        flag_remove_values_by_percentage=False,\n",
        "        percentage_to_remove_column=0,\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1716433441170
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import datetime as dt\n",
        "\n",
        "models = ['nbc', 'gbc', 'rfc', 'svc', 'xgb']\n",
        "\n",
        "def _get_experiment_names() -> [str]:\n",
        "    experiment_names = []\n",
        "    for train_name, test_name in zip(TRAIN_DATAS, TEST_DATAS):\n",
        "        for model_name in models:\n",
        "            current_time = dt.datetime.now()\n",
        "            formatted_time = current_time.strftime(\"%Y_%m_%d_%H_%M_%S\")  # Formata a data e hora atual\n",
        "            train_name_base = train_name.split('.')[0]\n",
        "            test_name_base = test_name.split('.')[0]\n",
        "            name = f\"{train_name_base}_tested_{test_name_base}_model_{model_name}_encoded_tfidf_data\"\n",
        "            experiment_names.append(name)\n",
        "            print(name)\n",
        "    return experiment_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1716471286642
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Bad pipe message: %s [b'\\xee\\x12\\xf6\\x84j\\xcd\\x8e\\xcdwr\\x02`\\xde\\xddY\\x9a\\x8c\\xbd \\xbf\\xe7\\xbb>\\xab\\xeaZ\\x99\\x1a\\x95\\x95\\xde\\x10O\\x8c\\xd9%\\x18Z\\x01\\xe9)\\xda\\x14?\\x8d\\xe4N\\x19\\xd1\\x08\\x1d\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04', b'\\x03\\x06', b'\\x07\\x08']\n",
            "Bad pipe message: %s [b'\\t\\x08\\n\\x08\\x0b\\x08\\x04']\n",
            "Bad pipe message: %s [b'\\x08\\x06\\x04\\x01\\x05\\x01\\x06', b'']\n",
            "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 \\x19)k\\x1b)\\xdbN2\\x94Y\\xdc\\xf6BA\\xf6\\x0c&\\x9d,\\x84\\xd63']\n",
            "Bad pipe message: %s [b\"\\xe7\\xb9\\x1fx;IY\\xa4\\xc7\\xafY\\xaf\\xb5\\xe5\\x10\\x98\\r\\xd4\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\"]\n",
            "Bad pipe message: %s [b'']\n",
            "Bad pipe message: %s [b'', b'\\x03\\x03']\n",
            "Bad pipe message: %s [b'']\n",
            "Bad pipe message: %s [b'', b'\\x02']\n",
            "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
            "Bad pipe message: %s [b'H\\xfd\\xc2u\\xb6z\\xba\\xcc!\\xff\\xcbiqP\\xf3QJ{\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0', b'\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16']\n",
            "Bad pipe message: %s [b'\\xb9\\xec\\xd3\\x08]\\x86\\x8a\\xbb\\xfbC\\xf2\\xed\\x88-\\xf5\\xbb0B\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96']\n",
            "Bad pipe message: %s [b'\\x9f\\xa3\\x94\\\\\\x9f\\x9c\\xdd\\r\\x1f\\xc1\\x08t\\x14\\xc9\\xbfd\\xf3\\xd4\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16']\n",
            "Bad pipe message: %s [b'\\x0c\\xeb\\xbev\\xf7?\\xaa#\\xba\\xf9J\\xa6\\xe7\\xe1Z]\\x1b\\x1f\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00', b'\\x17\\x00\\x03\\xc0\\x10']\n",
            "Bad pipe message: %s [b\"\\x8b,J\\x82\\xe7\\x8ef\\xff*.\\xfa\\x7f\\x91\\x0bN\\x95\\xf7\\xe3\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\"]\n",
            "Bad pipe message: %s [b'\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00']\n",
            "Bad pipe message: %s [b'\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\\x04\\x01\\x04\\x02\\x04\\x03\\x03\\x01\\x03\\x02\\x03\\x03\\x02\\x01\\x02\\x02\\x02\\x03\\x00\\x0f\\x00\\x01\\x01']\n",
            "Bad pipe message: %s [b'\\xae\\xb7a', b'\\x1c\\x15\\xfd\\x91C\\x1b\\x8bN\\x98\\xc0:\\xf8D\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00']\n",
            "Bad pipe message: %s [b\"\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\"]\n",
            "Bad pipe message: %s [b'\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vrex_encoded_tf_idf_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017__tested_vrex_encoded_tf_idf_2018_2019_2020_2021__model_nbc_encoded_tfidf_data\n",
            "vrex_encoded_tf_idf_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017__tested_vrex_encoded_tf_idf_2018_2019_2020_2021__model_gbc_encoded_tfidf_data\n",
            "vrex_encoded_tf_idf_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017__tested_vrex_encoded_tf_idf_2018_2019_2020_2021__model_rfc_encoded_tfidf_data\n",
            "vrex_encoded_tf_idf_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017__tested_vrex_encoded_tf_idf_2018_2019_2020_2021__model_svc_encoded_tfidf_data\n",
            "vrex_encoded_tf_idf_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017__tested_vrex_encoded_tf_idf_2018_2019_2020_2021__model_xgb_encoded_tfidf_data\n",
            "RunId: plum_pear_l3pyrnv63c\n",
            "Web View: https://ml.azure.com/runs/plum_pear_l3pyrnv63c?wsid=/subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments\n",
            "\n",
            "Streaming logs/azureml/executionlogs.txt\n",
            "========================================\n",
            "\n",
            "[2024-05-23 03:04:10Z] Submitting 1 runs, first five are: 7aaf7449:3985ebea-8a2a-4499-adea-a594bf010404\n",
            "[2024-05-23 03:09:32Z] Completing processing run id 3985ebea-8a2a-4499-adea-a594bf010404.\n",
            "[2024-05-23 03:09:32Z] Submitting 1 runs, first five are: ca94341d:9e872cde-4c6c-423a-9649-f0601835880a\n",
            "[2024-05-23 03:14:56Z] Completing processing run id 9e872cde-4c6c-423a-9649-f0601835880a.\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: plum_pear_l3pyrnv63c\n",
            "Web View: https://ml.azure.com/runs/plum_pear_l3pyrnv63c?wsid=/subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments\n",
            "\n",
            "RunId: serene_skin_bk99nk13xn\n",
            "Web View: https://ml.azure.com/runs/serene_skin_bk99nk13xn?wsid=/subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments\n",
            "\n",
            "Streaming logs/azureml/executionlogs.txt\n",
            "========================================\n",
            "\n",
            "[2024-05-23 03:15:39Z] Completing processing run id 5e887b39-ce56-4319-8edc-fc70abf09b6f.\n",
            "[2024-05-23 03:15:40Z] Submitting 1 runs, first five are: b43ce941:631a97ac-094d-4937-9df0-2ab76a094ea2\n",
            "[2024-05-23 05:17:23Z] Completing processing run id 631a97ac-094d-4937-9df0-2ab76a094ea2.\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: serene_skin_bk99nk13xn\n",
            "Web View: https://ml.azure.com/runs/serene_skin_bk99nk13xn?wsid=/subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments\n",
            "\n",
            "RunId: maroon_pear_zzg9fyk79h\n",
            "Web View: https://ml.azure.com/runs/maroon_pear_zzg9fyk79h?wsid=/subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments\n",
            "\n",
            "Streaming logs/azureml/executionlogs.txt\n",
            "========================================\n",
            "\n",
            "[2024-05-23 05:18:23Z] Completing processing run id 6bbb1ace-b454-4b49-8352-0c7fa0197b8b.\n",
            "[2024-05-23 05:18:24Z] Submitting 1 runs, first five are: 1d351cea:4b0f02e4-9780-41d4-bbb2-8a7abe023ec4\n",
            "[2024-05-23 05:29:44Z] Completing processing run id 4b0f02e4-9780-41d4-bbb2-8a7abe023ec4.\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: maroon_pear_zzg9fyk79h\n",
            "Web View: https://ml.azure.com/runs/maroon_pear_zzg9fyk79h?wsid=/subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments\n",
            "\n",
            "RunId: boring_stone_0cfcs1ts2g\n",
            "Web View: https://ml.azure.com/runs/boring_stone_0cfcs1ts2g?wsid=/subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments\n",
            "\n",
            "Streaming logs/azureml/executionlogs.txt\n",
            "========================================\n",
            "\n",
            "[2024-05-23 05:30:48Z] Completing processing run id 5d435922-32a7-48b8-bc5f-a35da2a46fb7.\n",
            "[2024-05-23 05:30:49Z] Submitting 1 runs, first five are: 890dd584:2cbc16a2-4010-41e2-a07e-e50e93f20862\n",
            "[2024-05-23 09:31:59Z] Completing processing run id 2cbc16a2-4010-41e2-a07e-e50e93f20862.\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: boring_stone_0cfcs1ts2g\n",
            "Web View: https://ml.azure.com/runs/boring_stone_0cfcs1ts2g?wsid=/subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments\n",
            "\n",
            "RunId: cyan_tiger_2zyyvqjqlk\n",
            "Web View: https://ml.azure.com/runs/cyan_tiger_2zyyvqjqlk?wsid=/subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments\n",
            "\n",
            "Streaming logs/azureml/executionlogs.txt\n",
            "========================================\n",
            "\n",
            "[2024-05-23 09:32:52Z] Completing processing run id 205ad0ff-2394-4d5e-8687-7aa69bbfb663.\n",
            "[2024-05-23 09:32:53Z] Submitting 1 runs, first five are: 2822eddb:2d918cdb-ec3a-411d-bdc0-2feba96fce2b\n",
            "[2024-05-23 13:34:04Z] Completing processing run id 2d918cdb-ec3a-411d-bdc0-2feba96fce2b.\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: cyan_tiger_2zyyvqjqlk\n",
            "Web View: https://ml.azure.com/runs/cyan_tiger_2zyyvqjqlk?wsid=/subscriptions/da6ec459-95c4-4f18-8440-d275df8d38b7/resourcegroups/tcc-exp-rg/workspaces/tcc-experiments\n",
            "\n"
          ]
        }
      ],
      "source": [
        "experiment_names = _get_experiment_names()\n",
        "for pipeline, experiment_name in zip(pipelines, experiment_names):\n",
        "    pipeline_job = ml_client.jobs.create_or_update(\n",
        "        pipeline,\n",
        "        experiment_name=experiment_name,\n",
        "    )\n",
        "    ml_client.jobs.stream(pipeline_job.name)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "azureml_py310_sdkv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
